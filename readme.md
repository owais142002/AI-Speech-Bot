# Project README

## Overview

This project consists of a React-based frontend that listens to user queries, sends them to a Flask backend, and receives responses generated by a locally set up Llama3 language model. The backend handles the processing and communication with the LLM to provide intelligent answers to the queries.

## Project Structure

- **frontend/**: Contains the React application code.
- **backend/**: Contains the Flask application code and configuration for the Llama3 language model.

## Getting Started

### Prerequisites

- Node.js and npm installed on your machine.
- Python and pip installed on your machine.
- Llama3 language model set up locally.

### Running the Frontend

1. Navigate to the `frontend` directory:

   ```bash
   cd frontend
